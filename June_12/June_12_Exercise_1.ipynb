{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f395e7b-da8f-4a23-95bc-5c2407470fbc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## Dataset: sales_data.json (nested JSON)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "aef2afb2-fa25-4d67-a865-1d552d3fe67f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<pyspark.sql.connect.session.SparkSession at 0x7f94a98d5f10>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "spark = SparkSession.builder \\\n",
    "                    .appName(\"Exercise_1\") \\\n",
    "                .getOrCreate()\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5fb6570b-9845-43e8-bad8-52b9028064b3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------------------------------------------------+------+------+\n|OrderID|Customer|Items                                                         |Region|Amount|\n+-------+--------+--------------------------------------------------------------+------+------+\n|101    |Ali     |[{Product -> Laptop, Qty -> 1}, {Product -> Mouse, Qty -> 2}] |Asia  |1200.0|\n|102    |Zara    |[{Product -> Tablet, Qty -> 1}]                               |Europe|650.0 |\n|103    |Mohan   |[{Product -> Phone, Qty -> 2}, {Product -> Charger, Qty -> 1}]|Asia  |890.0 |\n|104    |Sara    |[{Product -> Desk, Qty -> 1}]                                 |US    |450.0 |\n+-------+--------+--------------------------------------------------------------+------+------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import Row \n",
    "data = [ \n",
    "        Row(OrderID=101, Customer=\"Ali\", Items=[{\"Product\":\"Laptop\", \"Qty\":1}, \n",
    "        {\"Product\":\"Mouse\", \"Qty\":2}], Region=\"Asia\", Amount=1200.0), \n",
    "        Row(OrderID=102, Customer=\"Zara\", Items=[{\"Product\":\"Tablet\", \"Qty\":1}], \n",
    "        Region=\"Europe\", Amount=650.0), \n",
    "        Row(OrderID=103, Customer=\"Mohan\", Items=[{\"Product\":\"Phone\", \"Qty\":2}, \n",
    "        {\"Product\":\"Charger\", \"Qty\":1}], Region=\"Asia\", Amount=890.0), \n",
    "        Row(OrderID=104, Customer=\"Sara\", Items=[{\"Product\":\"Desk\", \"Qty\":1}], \n",
    "        Region=\"US\", Amount=450.0) \n",
    "        ] \n",
    "df_sales = spark.createDataFrame(data) \n",
    "df_sales.show(truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "23bfd070-f80c-402e-817e-bcd72efa85c9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## PySpark Exercises â€“ Set 4 (SQL, JSON, Advanced Functions)\n",
    "### Working with JSON & Nested Fields\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b5e684f3-15c4-4303-8614-8c190546c991",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "1. Flatten the Items array using explode() to create one row per product ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "32791a69-4b50-4921-8980-09b98f5588f7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+------+------+--------------------+\n|OrderID|Customer|               Items|Region|Amount|                Item|\n+-------+--------+--------------------+------+------+--------------------+\n|    101|     Ali|[{Product -> Lapt...|  Asia|1200.0|{Product -> Lapto...|\n|    101|     Ali|[{Product -> Lapt...|  Asia|1200.0|{Product -> Mouse...|\n|    102|    Zara|[{Product -> Tabl...|Europe| 650.0|{Product -> Table...|\n|    103|   Mohan|[{Product -> Phon...|  Asia| 890.0|{Product -> Phone...|\n|    103|   Mohan|[{Product -> Phon...|  Asia| 890.0|{Product -> Charg...|\n|    104|    Sara|[{Product -> Desk...|    US| 450.0|{Product -> Desk,...|\n+-------+--------+--------------------+------+------+--------------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, explode\n",
    "sales_df = df_sales.withColumn(\"Item\", explode(\"Items\"))\n",
    "sales_df.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "354a7cac-7b04-454b-a138-b979e233f7b0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "2. Count total quantity sold per product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "04b4f3aa-d283-42f0-b42e-db20275599ef",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n|Product|TotalQuantity|\n+-------+-------------+\n|  Mouse|            2|\n| Laptop|            1|\n| Tablet|            1|\n|Charger|            1|\n|  Phone|            2|\n|   Desk|            1|\n+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.types import IntegerType\n",
    "sales_df = sales_df.withColumn(\"Product\", col(\"Item.Product\")) \\\n",
    "                   .withColumn(\"Quantity\", col(\"Item.Qty\").cast(\"int\"))\n",
    "\n",
    "sales_df.groupBy(\"Product\") \\\n",
    "        .sum(\"Quantity\") \\\n",
    "        .withColumnRenamed(\"sum(Quantity)\", \"TotalQuantity\") \\\n",
    "        .show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "53e08a11-0bc0-4173-9458-5aaca70ada63",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "3. Count number of orders per region."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9936785-eed8-47c1-83f3-0f23d6df92f9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+------+------+--------------------+-------+--------+\n|OrderID|Customer|               Items|Region|Amount|                Item|Product|Quantity|\n+-------+--------+--------------------+------+------+--------------------+-------+--------+\n|    101|     Ali|[{Product -> Lapt...|  Asia|1200.0|{Product -> Lapto...| Laptop|       1|\n|    101|     Ali|[{Product -> Lapt...|  Asia|1200.0|{Product -> Mouse...|  Mouse|       2|\n|    102|    Zara|[{Product -> Tabl...|Europe| 650.0|{Product -> Table...| Tablet|       1|\n|    103|   Mohan|[{Product -> Phon...|  Asia| 890.0|{Product -> Phone...|  Phone|       2|\n|    103|   Mohan|[{Product -> Phon...|  Asia| 890.0|{Product -> Charg...|Charger|       1|\n|    104|    Sara|[{Product -> Desk...|    US| 450.0|{Product -> Desk,...|   Desk|       1|\n+-------+--------+--------------------+------+------+--------------------+-------+--------+\n\n+------+-----------+\n|Region|TotalOrders|\n+------+-----------+\n|  Asia|          4|\n|Europe|          1|\n|    US|          1|\n+------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "sales_df.groupBy(col('Region')) \\\n",
    "        .count() \\\n",
    "        .withColumnRenamed(\"count\", \"TotalOrders\")\\\n",
    "        .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "50fabed6-c2ff-4d5c-a4af-194b548609e2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Using when and otherwise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "b2916b26-50ce-4a0a-ab77-4ff89acf6240",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "4.  Create a new column \\\n",
    "HighValueOrder : \\\n",
    "\"Yes\" if Amount > 1000\n",
    "\"No\" otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c1c323b7-0b98-4c3a-bd56-cc6e0263d85b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+------+--------------+\n|OrderID|Customer|Amount|HighValueOrder|\n+-------+--------+------+--------------+\n|    101|     Ali|1200.0|           Yes|\n|    101|     Ali|1200.0|           Yes|\n|    102|    Zara| 650.0|            No|\n|    103|   Mohan| 890.0|            No|\n|    103|   Mohan| 890.0|            No|\n|    104|    Sara| 450.0|            No|\n+-------+--------+------+--------------+\n\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import when\n",
    "sales_df = sales_df.withColumn(\"HighValueOrder\", \n",
    "                               when(col('Amount') > 1000, \"Yes\")\n",
    "                               .otherwise(\"No\")\n",
    "                               )\n",
    "sales_df.select(\n",
    "                \"OrderID\",\n",
    "                \"Customer\",\n",
    "                \"Amount\",\n",
    "                \"HighValueOrder\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "693fd779-e7d2-49ff-936a-c7ad99e21f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "5.  Add a column ShippingZone : \\\n",
    " Asia â†’ \"Zone A\", Europe â†’ \"Zone B\", US â†’ \"Zone C\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4b12e2a1-c03a-4bee-98d9-216098655de1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+------------+\n|Customer|Region|ShippingZone|\n+--------+------+------------+\n|     Ali|  Asia|      Zone A|\n|     Ali|  Asia|      Zone A|\n|    Zara|Europe|      Zone B|\n|   Mohan|  Asia|      Zone A|\n|   Mohan|  Asia|      Zone A|\n|    Sara|    US|      Zone C|\n+--------+------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "sales_df = sales_df.withColumn(\"ShippingZone\", \n",
    "                               when(col('Region') == \"Asia\", \"Zone A\") \\\n",
    "                               .when(col('Region') == \"Europe\", \"Zone B\") \\\n",
    "                               .when(col('Region') == \"US\", \"Zone C\"))\n",
    "sales_df.select(\n",
    "                \"Customer\",\n",
    "                \"Region\",\n",
    "                \"ShippingZone\"\n",
    ").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dc8199ab-1ea6-4c88-bacd-271173459761",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Temporary & Permanent Views"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f31138ad-ff2b-4126-be2c-6383785a3bf0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "6. Register df_sales as a temporary view named sales_view ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3ddfcdab-7a21-4c56-9d26-8ac3198efd6e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_df.createOrReplaceTempView(\"sales_view\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "95d5b0ff-b154-44a2-9dbf-4f900df9bcc8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "7. Write a SQL query to: \\\n",
    "o count orders by Region \\\n",
    "o Find average amount per region \\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c056f850-bb42-46c8-8b5c-091e2b0b8b1e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------+-------+--------+------+--------------+-----------------+\n|OrderID|Region|Product|Quantity|Amount|OrdersByRegion|AvgAmountByRegion|\n+-------+------+-------+--------+------+--------------+-----------------+\n|    101|  Asia| Laptop|       1|1200.0|             4|           1045.0|\n|    101|  Asia|  Mouse|       2|1200.0|             4|           1045.0|\n|    103|  Asia|  Phone|       2| 890.0|             4|           1045.0|\n|    103|  Asia|Charger|       1| 890.0|             4|           1045.0|\n|    102|Europe| Tablet|       1| 650.0|             1|            650.0|\n|    104|    US|   Desk|       1| 450.0|             1|            450.0|\n+-------+------+-------+--------+------+--------------+-----------------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    SELECT\n",
    "        OrderID,\n",
    "        Region,\n",
    "        Product,\n",
    "        Quantity,\n",
    "        Amount,\n",
    "        COUNT(OrderID) OVER (PARTITION BY Region) AS OrdersByRegion,\n",
    "        AVG(Amount) OVER (PARTITION BY Region) AS AvgAmountByRegion\n",
    "    FROM sales_view\n",
    "\"\"\").show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f52d2179-8d36-4c9a-b4d0-d2e14164dbe1",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "8. Create a permanent view using saveAsTable() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ba79cbb0-5ab9-42ab-bcd8-357da95456ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------+--------------------+------+------+--------------------+-------+--------+--------------+------------+\n|OrderID|Customer|               Items|Region|Amount|                Item|Product|Quantity|HighValueOrder|ShippingZone|\n+-------+--------+--------------------+------+------+--------------------+-------+--------+--------------+------------+\n|    101|     Ali|[{Product -> Lapt...|  Asia|1200.0|{Product -> Lapto...| Laptop|       1|           Yes|      Zone A|\n|    101|     Ali|[{Product -> Lapt...|  Asia|1200.0|{Product -> Mouse...|  Mouse|       2|           Yes|      Zone A|\n|    102|    Zara|[{Product -> Tabl...|Europe| 650.0|{Product -> Table...| Tablet|       1|            No|      Zone B|\n|    103|   Mohan|[{Product -> Phon...|  Asia| 890.0|{Product -> Phone...|  Phone|       2|            No|      Zone A|\n|    103|   Mohan|[{Product -> Phon...|  Asia| 890.0|{Product -> Charg...|Charger|       1|            No|      Zone A|\n|    104|    Sara|[{Product -> Desk...|    US| 450.0|{Product -> Desk,...|   Desk|       1|            No|      Zone C|\n+-------+--------+--------------------+------+------+--------------------+-------+--------+--------------+------------+\n\n"
     ]
    }
   ],
   "source": [
    "sales_df.write.mode(\"overwrite\").saveAsTable(\"sales_permanent_table\")\n",
    "\n",
    "spark.sql(\"select * from sales_permanent_table\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7b364026-c919-4388-955e-03fe911ae01a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###  SQL Queries via Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b60d0d86-ab89-4cde-a1a2-a84730ca2a6d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+----------+\n|Region|OrderCount|\n+------+----------+\n|  Asia|         4|\n|Europe|         1|\n|    US|         1|\n+------+----------+\n\n"
     ]
    }
   ],
   "source": [
    " spark.sql(\"\"\"\n",
    "            SELECT \n",
    "                Region, \n",
    "                COUNT(*) as OrderCount \n",
    "            FROM sales_view \n",
    "            GROUP BY Region\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "2c7c809f-c4fe-4424-83e7-667f846c6cf6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "9. Use SQL to filter all orders with more than 1 item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "93621687-acf2-45ff-95ad-4fe0d6bfe3da",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+--------+-------+\n|OrderID|Product|Quantity|row_num|\n+-------+-------+--------+-------+\n|    101| Laptop|       1|      2|\n|    103|Charger|       1|      2|\n+-------+-------+--------+-------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            WITH OrderInfo AS(\n",
    "                            SELECT\n",
    "                                OrderID,\n",
    "                                Product,\n",
    "                                Quantity,\n",
    "                                ROW_NUMBER() OVER(PARTITION BY OrderID ORDER BY Quantity DESC) as row_num\n",
    "                            FROM sales_view)\n",
    "            SELECT * \n",
    "            FROM OrderInfo\n",
    "            WHERE row_num > 1\n",
    "        \n",
    "          \"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9a127be2-1a80-4309-8ac3-c4c33aaed61f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "10. Use SQL to extract customer names where Amount > 800."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "08402d6f-ac83-40cb-b990-80b16b8118dd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n|Customer|TotalAmount|\n+--------+-----------+\n|     Ali|     2400.0|\n|    Zara|      650.0|\n|   Mohan|     1780.0|\n|    Sara|      450.0|\n+--------+-----------+\n\n"
     ]
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "            SELECT\n",
    "                Customer,\n",
    "                SUM(Amount) AS TotalAmount\n",
    "            FROM sales_view\n",
    "            GROUP BY(Customer)\n",
    "          \"\"\"\n",
    "          ).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "f482a29a-071b-4d2d-9348-3be41ac957e8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Saving as Parquet and Reading Again"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f6c3007-75fa-45b2-b802-42026f3e1867",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "11. Save the exploded product-level DataFrame as a partitioned Parquet file by\n",
    " Region ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6a94c076-c270-49cb-8749-0dcf3a555ffb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "exploded_df = df_sales.withColumn(\"Item\", explode(col(\"Items\"))) \\\n",
    "                      .select(\n",
    "                          \"OrderID\", \n",
    "                          \"Customer\", \n",
    "                          \"Region\", \n",
    "                          \"Amount\", \n",
    "                          col(\"Item.Product\").alias(\"Product\"), \n",
    "                          col(\"Item.Qty\").alias(\"Quantity\")\n",
    "                      )\n",
    "\n",
    "exploded_df.write.mode('Overwrite')\\\n",
    "           .partitionBy(\"Region\") \\\n",
    "           .parquet(\"dbfs:/FileStore/exploded_parquet\")\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a56c45de-ce2c-4bbe-bf71-18fee617c241",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "12. Read the parquet back and perform a group-by on \n",
    "Product "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "edd0a6fd-18ae-440a-847c-e9f82dce79a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------------+\n|Product|TotalQuantity|\n+-------+-------------+\n|  Phone|            2|\n|  Mouse|            2|\n| Laptop|            1|\n| Tablet|            1|\n|Charger|            1|\n|   Desk|            1|\n+-------+-------------+\n\n"
     ]
    }
   ],
   "source": [
    "exploded_df_loaded = spark.read.parquet(\"dbfs:/FileStore/exploded_parquet\")\n",
    "exploded_df_loaded.groupBy(col('Product')) \\\n",
    "                  .agg(sum('Quantity').cast(\"int\").alias(\"TotalQuantity\")) \\\n",
    "                  .orderBy('TotalQuantity', ascending=False) \\\n",
    "                  .show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "June_12_Exercise_1",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}