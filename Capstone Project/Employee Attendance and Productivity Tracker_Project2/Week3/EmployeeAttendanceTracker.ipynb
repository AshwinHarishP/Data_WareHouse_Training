{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Importing Packages and Creating a new spark session"
      ],
      "metadata": {
        "id": "PThKN41cs-3l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "8I1PvIzWs1Yt"
      },
      "outputs": [],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import avg, round, max, date_format, to_date, to_timestamp, col, count, coalesce, lit\n",
        "from google.colab import drive"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Creating Session"
      ],
      "metadata": {
        "id": "fbCuCvvheGuQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "                    .appName(\"Employee Attendance Tracker\") \\\n",
        "                    .getOrCreate()\n",
        "spark"
      ],
      "metadata": {
        "id": "ALr7HeVXeIrY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reading CSV File from Google Drive"
      ],
      "metadata": {
        "id": "Ui5HAi42tugr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "drive.mount('/content/drive')\n",
        "attendance_df = spark.read.csv('/content/drive/MyDrive/CapstoneProjectData/Employee/attendance.csv', header=True, inferSchema=True)\n",
        "employee_df = spark.read.csv('/content/drive/MyDrive/CapstoneProjectData/Employee/employees.csv', header=True, inferSchema=True)\n",
        "task_df = spark.read.csv('/content/drive/MyDrive/CapstoneProjectData/Employee/tasks.csv', header=True, inferSchema=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c_2LZGsxtJiA",
        "outputId": "fee6352b-6712-411f-ed66-b9b8cfe07131"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "attendance_df.show()\n",
        "employee_df.show()\n",
        "task_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n89Uq2tyvDh1",
        "outputId": "5118542a-da9f-4648-edcd-45a8643ae371"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------------+-------------------+-------------------+-------------------+\n",
            "|employee_id|           clock_in|          clock_out|        break_start|          break_end|\n",
            "+-----------+-------------------+-------------------+-------------------+-------------------+\n",
            "|          1|2025-06-01 09:00:00|2025-06-01 17:30:00|2025-06-01 13:00:00|2025-06-01 13:30:00|\n",
            "|          1|2025-06-02 09:15:00|2025-06-02 18:00:00|2025-06-02 13:15:00|2025-06-02 13:45:00|\n",
            "|          2|2025-06-01 09:20:00|2025-06-01 17:00:00|2025-06-01 13:10:00|2025-06-01 13:40:00|\n",
            "|          2|2025-06-02 09:00:00|2025-06-02 16:50:00|2025-06-02 12:50:00|2025-06-02 13:20:00|\n",
            "|          3|2025-06-01 08:50:00|2025-06-01 16:40:00|2025-06-01 12:50:00|2025-06-01 13:15:00|\n",
            "|          3|2025-06-02 09:10:00|2025-06-02 17:10:00|2025-06-02 13:00:00|2025-06-02 13:35:00|\n",
            "|          4|2025-06-01 09:00:00|2025-06-01 17:15:00|2025-06-01 13:00:00|2025-06-01 13:25:00|\n",
            "|          4|2025-06-02 08:45:00|2025-06-02 17:00:00|2025-06-02 12:45:00|2025-06-02 13:10:00|\n",
            "|          5|2025-06-01 09:30:00|2025-06-01 18:00:00|2025-06-01 13:30:00|2025-06-01 14:00:00|\n",
            "|          5|2025-06-02 09:15:00|2025-06-02 17:45:00|2025-06-02 13:15:00|2025-06-02 13:45:00|\n",
            "|          6|2025-06-01 09:10:00|2025-06-01 17:00:00|2025-06-01 13:05:00|2025-06-01 13:35:00|\n",
            "|          6|2025-06-02 09:20:00|2025-06-02 17:50:00|2025-06-02 13:20:00|2025-06-02 13:50:00|\n",
            "|          7|2025-06-01 09:05:00|2025-06-01 17:20:00|2025-06-01 13:00:00|2025-06-01 13:30:00|\n",
            "|          7|2025-06-02 09:10:00|2025-06-02 17:40:00|2025-06-02 13:10:00|2025-06-02 13:40:00|\n",
            "|          8|2025-06-01 09:00:00|2025-06-01 17:10:00|2025-06-01 13:00:00|2025-06-01 13:25:00|\n",
            "|          8|2025-06-02 09:15:00|2025-06-02 17:35:00|2025-06-02 13:15:00|2025-06-02 13:45:00|\n",
            "|          9|2025-06-01 08:50:00|2025-06-01 16:50:00|2025-06-01 12:50:00|2025-06-01 13:15:00|\n",
            "|          9|2025-06-02 09:05:00|2025-06-02 17:05:00|2025-06-02 13:05:00|2025-06-02 13:35:00|\n",
            "|         10|2025-06-01 09:00:00|2025-06-01 17:25:00|2025-06-01 13:00:00|2025-06-01 13:30:00|\n",
            "|         10|2025-06-02 09:20:00|2025-06-02 17:50:00|2025-06-02 13:20:00|2025-06-02 13:50:00|\n",
            "+-----------+-------------------+-------------------+-------------------+-------------------+\n",
            "\n",
            "+-----------+-------------+----------+\n",
            "|employee_id|employee_name|department|\n",
            "+-----------+-------------+----------+\n",
            "|          1|       Ashwin|        IT|\n",
            "|          2|      Aravind|        HR|\n",
            "|          3|     Akhilesh|   Finance|\n",
            "|          4|         Neha|        IT|\n",
            "|          5|        Rahul|        HR|\n",
            "|          6|        Pooja|   Finance|\n",
            "|          7|       Suresh|        IT|\n",
            "|          8|        Anita|        HR|\n",
            "|          9|       Vikram|   Finance|\n",
            "|         10|        Rohit|        IT|\n",
            "|         11|        Sneha|        HR|\n",
            "|         12|        Karan|   Finance|\n",
            "|         13|        Deepa|        IT|\n",
            "|         14|       Ramesh|        HR|\n",
            "|         15|        Priya|   Finance|\n",
            "|         16|        Manoj|        IT|\n",
            "|         17|       Kavita|        HR|\n",
            "|         18|         Ajay|   Finance|\n",
            "|         19|       Sunita|        IT|\n",
            "|         20|        Vikas|        HR|\n",
            "+-----------+-------------+----------+\n",
            "\n",
            "+-----------+--------------------+----------+\n",
            "|employee_id|    task_description| task_date|\n",
            "+-----------+--------------------+----------+\n",
            "|          1|Prepare project r...|2025-06-01|\n",
            "|          2|  Conduct interviews|2025-06-01|\n",
            "|          3|Review financial ...|2025-06-01|\n",
            "|          4|   Develop feature X|2025-06-01|\n",
            "|          5|Organize team mee...|2025-06-01|\n",
            "|          6|Update documentation|2025-06-01|\n",
            "|          7|Fix bugs in module Y|2025-06-01|\n",
            "|          8|Plan training ses...|2025-06-01|\n",
            "|          9|      Audit accounts|2025-06-01|\n",
            "|         10|  Deploy new release|2025-06-01|\n",
            "|         11|Coordinate client...|2025-06-01|\n",
            "|         12|   Design UI mockups|2025-06-01|\n",
            "|         13|    Prepare invoices|2025-06-01|\n",
            "|         14|Conduct performan...|2025-06-01|\n",
            "|         15|          Update CRM|2025-06-01|\n",
            "|         16|  Research new tools|2025-06-01|\n",
            "|         17|  Organize workshops|2025-06-01|\n",
            "|         18|       Test software|2025-06-01|\n",
            "|         19|Prepare presentat...|2025-06-01|\n",
            "|         20|Maintain server u...|2025-06-01|\n",
            "+-----------+--------------------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Converting  String to timestamp data type"
      ],
      "metadata": {
        "id": "edzUPciHvgt2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attendance_df = attendance_df.withColumn(\"clock_in\", col(\"clock_in\").cast(\"timestamp\")) \\\n",
        "                             .withColumn(\"clock_out\", col(\"clock_out\").cast(\"timestamp\"))"
      ],
      "metadata": {
        "id": "2YWR6gLfvhSG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Extracting date and time from datetime timestamp"
      ],
      "metadata": {
        "id": "evR3_xBdt5Sa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attendance_df = attendance_df.withColumn(\"login_time\", date_format(\"clock_in\", \"HH:mm:ss\")) \\\n",
        "                             .withColumn(\"login_date\", to_date(\"clock_in\"))"
      ],
      "metadata": {
        "id": "jOEewcMDt5z1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filter for late logins"
      ],
      "metadata": {
        "id": "emnvHiIKvtpf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "late_logins_df = attendance_df.filter(col(\"login_time\") > \"09:00:00\") \\\n",
        "                              .select(\"employee_id\", \"login_time\", \"login_date\")\n",
        "\n",
        "late_logins_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TpGJW0-SvuDA",
        "outputId": "f95a4a71-b0cc-45ed-dc4e-b58324e82f2b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+----------+----------+\n",
            "|employee_id|login_time|login_date|\n",
            "+-----------+----------+----------+\n",
            "|          1|  09:15:00|2025-06-02|\n",
            "|          2|  09:20:00|2025-06-01|\n",
            "|          3|  09:10:00|2025-06-02|\n",
            "|          5|  09:30:00|2025-06-01|\n",
            "|          5|  09:15:00|2025-06-02|\n",
            "|          6|  09:10:00|2025-06-01|\n",
            "|          6|  09:20:00|2025-06-02|\n",
            "|          7|  09:05:00|2025-06-01|\n",
            "|          7|  09:10:00|2025-06-02|\n",
            "|          8|  09:15:00|2025-06-02|\n",
            "|          9|  09:05:00|2025-06-02|\n",
            "|         10|  09:20:00|2025-06-02|\n",
            "+-----------+----------+----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Filtering for absences\n"
      ],
      "metadata": {
        "id": "ccyzdBEQw7g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating new data frame for employees and dates\n",
        "employees_df = employee_df.select(\"employee_id\").distinct()\n",
        "attendance_df = attendance_df.withColumn(\"login_date\", to_date(\"clock_in\"))\n",
        "dates_df = attendance_df.select(\"login_date\").distinct()\n",
        "\n",
        "# Getting all combinations of employees and dates\n",
        "employee_date_df = employees_df.crossJoin(dates_df)\n",
        "\n",
        "# creating new data frame for employee who made attendance\n",
        "actual_attendance_df = attendance_df.select(\"employee_id\", \"login_date\").distinct()\n",
        "\n",
        "# Joining combinations of employees and dates and with actual attendance\n",
        "absentees_df = employee_date_df.join(\n",
        "    actual_attendance_df,\n",
        "    on=[\"employee_id\", \"login_date\"],\n",
        "    how=\"left_anti\"\n",
        ")\n",
        "\n",
        "# Joining absentees table with employee table\n",
        "absentees_df = absentees_df.withColumnRenamed(\"login_date\", \"absent_date\") \\\n",
        "                           .join(employee_df, on=\"employee_id\", how=\"left\") \\\n",
        "                           .select(\"employee_id\", \"employee_name\", \"department\", \"absent_date\")\n",
        "\n",
        "# Displays the null records -> Absentees\n",
        "absentees_df.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KUuwUetrw_8Y",
        "outputId": "41fa6255-7259-4606-c29b-683c88e61043"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+-----------+-------------+----------+-----------+\n",
            "|employee_id|employee_name|department|absent_date|\n",
            "+-----------+-------------+----------+-----------+\n",
            "|         12|        Karan|   Finance| 2025-06-02|\n",
            "|         13|        Deepa|        IT| 2025-06-02|\n",
            "|         16|        Manoj|        IT| 2025-06-02|\n",
            "|         20|        Vikas|        HR| 2025-06-02|\n",
            "|         19|       Sunita|        IT| 2025-06-02|\n",
            "|         15|        Priya|   Finance| 2025-06-02|\n",
            "|         17|       Kavita|        HR| 2025-06-02|\n",
            "|         11|        Sneha|        HR| 2025-06-02|\n",
            "|         14|       Ramesh|        HR| 2025-06-02|\n",
            "|         18|         Ajay|   Finance| 2025-06-02|\n",
            "|         12|        Karan|   Finance| 2025-06-01|\n",
            "|         13|        Deepa|        IT| 2025-06-01|\n",
            "|         16|        Manoj|        IT| 2025-06-01|\n",
            "|         20|        Vikas|        HR| 2025-06-01|\n",
            "|         19|       Sunita|        IT| 2025-06-01|\n",
            "|         15|        Priya|   Finance| 2025-06-01|\n",
            "|         17|       Kavita|        HR| 2025-06-01|\n",
            "|         11|        Sneha|        HR| 2025-06-01|\n",
            "|         14|       Ramesh|        HR| 2025-06-01|\n",
            "|         18|         Ajay|   Finance| 2025-06-01|\n",
            "+-----------+-------------+----------+-----------+\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Group by department to get average work hours and productivity\n",
        "\n"
      ],
      "metadata": {
        "id": "rd0-r6U3FFRG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding working hours column\n",
        "attendance_df = attendance_df.withColumn(\n",
        "    \"work_hours\",\n",
        "    ((col(\"clock_out\").cast(\"long\") - col(\"clock_in\").cast(\"long\")) - (col(\"break_end\").cast(\"long\") - col(\"break_start\").cast(\"long\"))) / 3600.0\n",
        ")\n",
        "\n",
        "# Adding work date column\n",
        "attendance_df = attendance_df.withColumn(\"work_date\", to_date(col(\"clock_in\")))\n",
        "\n",
        "# Calculating productivity\n",
        "productivity_df = task_df.groupBy(\"employee_id\", \"task_date\").count().withColumnRenamed(\"count\", \"tasks_done\")\n",
        "\n",
        "# Joining attendance and productivity table\n",
        "attendance_productivity_df = attendance_df.join(\n",
        "    productivity_df,\n",
        "    (attendance_df.employee_id == productivity_df.employee_id) &\n",
        "    (attendance_df.work_date == productivity_df.task_date),\n",
        "     how=\"left\") \\\n",
        "    .select(\n",
        "    attendance_df.employee_id,\n",
        "    attendance_df.work_hours,\n",
        "    attendance_df.work_date,\n",
        "    coalesce(productivity_df.tasks_done, lit(0)).alias(\"tasks_done\")\n",
        "    )\n",
        "\n",
        "\n",
        "# joining attendance and employee table\n",
        "employee_attendance_df = attendance_productivity_df.join(employee_df, on=\"employee_id\", how=\"left\")\n",
        "\n",
        "# grouping by department and average work hours and average productivity\n",
        "result_df = employee_attendance_df.groupBy(\"department\") \\\n",
        "                   .agg(\n",
        "                       round(avg(\"work_hours\"),2).alias(\"avg_work_hours\"),\n",
        "                       avg(\"tasks_done\").alias(\"avg_productivity\")\n",
        "                   )\n",
        "\n",
        "result_df.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1T4JcxjcFF9g",
        "outputId": "d48d67c2-15d2-44c3-8a2e-edae3c06bb99"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------+----------------+\n",
            "|department|avg_work_hours|avg_productivity|\n",
            "+----------+--------------+----------------+\n",
            "|        HR|          7.68|             0.5|\n",
            "|   Finance|          7.54|             0.5|\n",
            "|        IT|          7.95|             0.5|\n",
            "+----------+--------------+----------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}